---
categories:
- ""
- ""
date: "2017-10-31T21:28:43-05:00"
description: ""
draft: false
image: bikes.jpeg
keywords: ""
slug: tfl
title: An insight into bike rentals
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
```

# How have bike rentals changed in London

As discussed in an earlier lecture, we will look at the daily cycle hires to assess the trends over time. The data source is provided by the government and covers daily Tfl cycle hires

*Source: https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx*

```{r, get_tfl_data, cache=TRUE, include=FALSE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

To get a better understanding of the data, we can plot out the usage by month 

```{r tfl_month_year_grid, echo=FALSE, out.width="100%", include=FALSE}
knitr::include_graphics("/img/tfl_distributions_monthly.png",error =FALSE)
```

## 2020 vs. Previous Years

The graphs of May and June in 2020 show a much flatter curve compared to those of previous years, which suggests that bikes distribution among these two months are more even across 20k, 40k, and 60k. In terms of potential reasons behind such change, it's likely that due to the lockdown policy in UK during the those two months of 2020, bike rentals as a result decreased dramatically. Since there has been restrictions on the use of public transportations, the bikes are rented on a much lower frenquency throughout the months.


```{r tfl_absolute_monthly_changes, out.width="100%", fig.width = 12}
# Create chart here
bike_expected_df <- bike %>% 
filter(day > "2015-12-31", day < "2020-01-01") %>% # calculate mean for 2016-2019 as stated in the chart
group_by(month) %>% # group by month to calculate monthly mean over the years 2016-2019
summarise(
  expected_rentals = mean(bikes_hired)
  )

bike_actual_df <- bike %>% 
filter(day > "2015-12-31") %>% # filter for years 2016 to current
group_by(month, year) %>%  # group by month and year to calculate monthly mean per year
summarise(
  actual_rentals = mean(bikes_hired)
) %>% 
left_join(bike_expected_df, by ="month") %>% # left join previous data frame with expected rentals to the new df with actuals
mutate(
  excess_bike_rentals = actual_rentals - expected_rentals, # calculate excess rentals over mean
  up = ifelse(actual_rentals>expected_rentals, excess_bike_rentals, 0), # filter deviations above mean
  down = ifelse(actual_rentals<expected_rentals, excess_bike_rentals, 0), # filter devations below mean
  up_plus_expected = expected_rentals + up, # expected + deveation above mean to create chart
  down_plus_expected = expected_rentals + down # expected + deveation below mean to create chart
) 

plot <- bike_actual_df %>% 
ggplot(aes(x = month, y = expected_rentals)) +
facet_wrap(vars(year)) +
geom_line(aes(y = expected_rentals), group = 1, color = "blue", lwd = 1.1) +
geom_line(aes(y = up_plus_expected), group = 1, lwd = 0.1) +
geom_line(aes(y = down_plus_expected), group = 1, lwd = 0.1) +
geom_ribbon(aes(ymin = expected_rentals,ymax = expected_rentals + up),fill="#7DCD85",alpha=0.4, group = 1) +
geom_ribbon(aes(ymin = expected_rentals + down , ymax = expected_rentals),fill="#CB454A",alpha=0.4, group = 1) +
labs(
  title = "Monthly changes in TfL rentals",
  subtitle = "Change from monthly average shown in blue and calculated between 2016-2019",
  caption = "Source: TfL, London Data Store",
  x = "Month",
  y = "Rentals"
) +
theme_bw() +
theme(panel.border = element_blank(), # remove border
      strip.background = element_blank() # remove background of headers
      ) + theme(axis.title.x = element_text(vjust = -2,size=14, face = "italic"), #adjust axis 
      axis.title.y = element_text(vjust = 3,size=14, face = "italic")) + 
scale_y_continuous(labels = comma)

plot



```

The second one looks at percentage changes from the expected level of weekly rentals. The two grey shaded rectangles correspond to Q2 (weeks 14-26) and Q4 (weeks 40-52).


The graph is the one below with labels on both axes!

```{r tfl_percent_change, out.width="100%", fig.width = 12, fig.height = 10}
bike_expected_week_df <- bike %>% 
filter(day > "2015-12-31", day < "2020-01-01") %>% # filter for years 2016-2019 to calcualte average
group_by(week) %>% 
summarise(
  expected_rentals = mean(bikes_hired),
  )

bike_actual_week_df <- bike %>% 
filter(day > "2015-12-31", day <= "2021-08-31") %>% # cut off values beyond August 2021
group_by(week, year) %>% # group by week and year, just as in the task before
summarise(
  actual_rentals = mean(bikes_hired)
) %>% 
left_join(bike_expected_week_df, by ="week") %>% # join tables with left_join (see above)
mutate(
  excess_bike_rentals = actual_rentals - expected_rentals,
  percentage = ifelse((year == 2021) & (week > 36), NA, actual_rentals / expected_rentals -1),
  up = ifelse(percentage > 0, percentage, 0),
  down = ifelse(percentage < 0, percentage, 0),
  up_ribbon = ifelse(percentage > 0, percentage, NA), # create extra calculation for ribbons with NA for geom_rug
  down_ribbon = ifelse(percentage < 0, percentage, NA) # create extra calculation for ribbons with NA for geom_rug
) 

q2 <- bike_actual_week_df %>% 
filter(week < 13, week < 27)

q4 <- bike_actual_week_df %>% 
filter(week < 39, week < 53)

#plot
plot <- bike_actual_week_df %>% 
ggplot(aes(x = week, y = percentage)) +
facet_wrap(vars(year)) +
geom_line(aes(y = percentage), group = 1, na.rm = FALSE, lwd = 0.1) +
geom_ribbon(aes(ymin = 0,ymax = up ),fill="#7DCD85",alpha=0.4, group = 1) +
geom_ribbon(aes(ymin = down , ymax = 0),fill="#CB454A",alpha=0.4, group = 1) +
geom_rug(aes(y = down_ribbon), position = "stack", color = "#CB454A", sides = "b", na.rm = TRUE, show.legend = NA) + # use position "stack" to make the tick intervals equal
geom_rug(aes(y = up_ribbon), position = "stack", color = "#7DCD85", sides = "b", na.rm = TRUE, show.legend = NA) + # use position "stack" to make the tick intervals equal
#geom_rect(data = q2, aes(xmin = 16, xmax = 26, ymin = 0, fill = t), color = "grey") +
geom_rect(aes(xmin=13, xmax=26, ymin=-0.5, ymax=1), fill="grey", alpha=.01) + # add grey tiles
geom_rect(aes(xmin=39, xmax=53, ymin=-0.5, ymax=1), fill="grey", alpha=.01) + # add grey tiles
scale_y_continuous(limits = c(-.5, 1), labels = scales::percent) + # limit scale according to provided image
scale_x_continuous(limits = c(0, 53), breaks = c(13, 26, 39, 53)) + # adjust breaks to fit example
theme_bw() +
theme(panel.border = element_blank(), # remove border
      strip.background = element_blank() # remove header background
      ) +
labs(title = "Weekly changes in TfL bike rentals",
     subtitle = "Percentage change from weekly averages calculated between 2016-2019",
     caption = "Source: TfL, London Data Store",
     x = "Week",
     y = "Percentage change from weekly average")

plot


```

If we need to find out the expected value, it always means the long term average or mean. Depending on the distribution and skewness of the data, mean can be a better estimate when the data is left or right skewed, or when the standard deviations can cancel each other off.